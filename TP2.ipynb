{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP Implémentation du modèle linéaire L1 régularisé\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puisqu'il y a du code fourni pour une application similaire je commence par l'éxécuter pour voir ce qu'il fait et ce qui sera réutilisable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator,ClassifierMixin\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import cross_validation\n",
    "class RandomOuSvmClassifier(BaseEstimator,ClassifierMixin):\n",
    "    \"\"\" si la nature du classifier est random il predit au hasard des 0 et\n",
    "    des 1 sinon il utilise un svm pour predire\"\"\"\n",
    "    def __init__(self,nature=\"random\"):\n",
    "        self.nature=nature\n",
    "        self.svm=SVC()\n",
    "    def fit(self, X, y):\n",
    "        if(self.nature==\"svm\"):\n",
    "            self.svm.fit(X, y)\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        if(self.nature==\"random\"):\n",
    "            return np.random.randint(0,2,len(X))\n",
    "        else:\n",
    "            return self.svm.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est visiblement l'implémentation d'un classifieur avec la même interface que ceux de sklearn, et donc la même que celle du classifieur demandé\n",
    "je jette un oeil aux docs de http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html et http://scikit-learn.org/stable/modules/generated/sklearn.base.ClassifierMixin.html pour voir s'il est nécessaire d'en hériter.(la doc dit que oui mais je ne comprends pas trop pourquoi...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "classifieurRandom= RandomOuSvmClassifier(nature=\"random\")\n",
    "classifieurSvm= RandomOuSvmClassifier(nature=\"svm\")\n",
    "scoresRandom = cross_validation.cross_val_score(classifieurRandom, X, y, cv=5\n",
    ",scoring=\"accuracy\")\n",
    "scoresSvm = cross_validation.cross_val_score(classifieurSvm, X, y, cv=5\n",
    ",scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.33333333,  0.4       ,  0.26666667,  0.26666667,  0.33333333])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoresRandom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.96666667,  1.        ,  0.96666667,  0.96666667,  1.        ])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoresSvm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce deuxième bout de code m'a donc montré comment charger un ensemble de données qui possède 3 classes (au vu du random effectué dans le predict et de ses résultats) Il faudra donc en utiliser un autre car notre classifications se fait sur 2 classes. Il me montre aussi comment utiliser la cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.float64'>\n",
      "<type 'numpy.int32'>\n",
      "[-1  1 -1  1 -1  1 -1 -1  1  1]\n",
      "(65L,)\n",
      "(287L, 64L)\n",
      "0\n",
      "1.0 coût\n",
      "0.0 accuracy\n",
      "500\n",
      "1.0 coût\n",
      "0.0 accuracy\n",
      "1000\n",
      "1.0 coût\n",
      "0.0 accuracy\n",
      "1500\n",
      "1.97909407666 coût\n",
      "0.505226480836 accuracy\n",
      "2000\n",
      "1.0 coût\n",
      "0.0 accuracy\n",
      "2500\n",
      "1.0 coût\n",
      "0.0 accuracy\n",
      "3000\n",
      "1.0 coût\n",
      "0.0 accuracy\n",
      "3500\n",
      "1.0 coût\n",
      "0.0 accuracy\n",
      "4000\n",
      "1.97909407666 coût\n",
      "0.505226480836 accuracy\n",
      "4500\n",
      "1.97909407666 coût\n",
      "0.505226480836 accuracy\n",
      "(65L,)\n",
      "(287L, 64L)\n",
      "0\n",
      "1.0 coût\n",
      "0.0 accuracy\n",
      "500\n",
      "1.0 coût\n",
      "0.0 accuracy\n",
      "1000\n",
      "1.0 coût\n",
      "0.0 accuracy\n",
      "1500\n",
      "1.0 coût\n",
      "0.0 accuracy\n",
      "2000\n",
      "1.0 coût\n",
      "0.0 accuracy\n",
      "2500\n",
      "1.0 coût\n",
      "0.0 accuracy\n",
      "3000\n",
      "2.02090592334 coût\n",
      "0.463414634146 accuracy\n",
      "3500\n",
      "1.97909407666 coût\n",
      "0.505226480836 accuracy\n",
      "4000\n",
      "1.97909407666 coût\n",
      "0.505226480836 accuracy\n",
      "4500\n",
      "1.97909407666 coût\n",
      "0.505226480836 accuracy\n",
      "(65L,)\n",
      "(288L, 64L)\n",
      "0\n",
      "1.0 coût\n",
      "0.0 accuracy\n",
      "500\n",
      "1.97222222222 coût\n",
      "0.506944444444 accuracy\n",
      "1000\n",
      "1.0 coût\n",
      "0.0 accuracy\n",
      "1500\n",
      "1.0 coût\n",
      "0.0 accuracy\n",
      "2000\n",
      "1.0 coût\n",
      "0.0 accuracy\n",
      "2500\n",
      "1.97222222222 coût\n",
      "0.506944444444 accuracy\n",
      "3000\n",
      "1.97222222222 coût\n",
      "0.506944444444 accuracy\n",
      "3500\n",
      "1.98263888889 coût\n",
      "0.496527777778 accuracy\n",
      "4000\n",
      "1.97222222222 coût\n",
      "0.506944444444 accuracy\n",
      "4500\n",
      "1.97222222222 coût\n",
      "0.506944444444 accuracy\n",
      "(65L,)\n",
      "(289L, 64L)\n",
      "0\n",
      "1.0 coût\n",
      "0.0 accuracy\n",
      "500\n",
      "1.0 coût\n",
      "0.0 accuracy\n",
      "1000\n",
      "1.97923875433 coût\n",
      "0.505190311419 accuracy\n",
      "1500\n",
      "1.97923875433 coût\n",
      "0.505190311419 accuracy\n",
      "2000\n",
      "1.98269896194 coût\n",
      "0.501730103806 accuracy\n",
      "2500\n",
      "1.0 coût\n",
      "0.0 accuracy\n",
      "3000\n",
      "1.97923875433 coût\n",
      "0.505190311419 accuracy\n",
      "3500\n",
      "1.97923875433 coût\n",
      "0.505190311419 accuracy\n",
      "4000\n",
      "1.97923875433 coût\n",
      "0.505190311419 accuracy\n",
      "4500\n",
      "1.97923875433 coût\n",
      "0.505190311419 accuracy\n",
      "(65L,)\n",
      "(289L, 64L)\n",
      "0\n",
      "1.0 coût\n",
      "0.0 accuracy\n",
      "500\n",
      "1.97923875433 coût\n",
      "0.505190311419 accuracy\n",
      "1000\n",
      "1.97923875433 coût\n",
      "0.505190311419 accuracy\n",
      "1500\n",
      "2.13494809689 coût\n",
      "0.349480968858 accuracy\n",
      "2000\n",
      "1.97923875433 coût\n",
      "0.505190311419 accuracy\n",
      "2500\n",
      "1.0 coût\n",
      "0.0 accuracy\n",
      "3000\n",
      "1.0 coût\n",
      "0.0 accuracy\n",
      "3500\n",
      "1.97923875433 coût\n",
      "0.505190311419 accuracy\n",
      "4000\n",
      "1.0 coût\n",
      "0.0 accuracy\n",
      "4500\n",
      "1.0 coût\n",
      "0.0 accuracy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator,ClassifierMixin\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from numpy.linalg import norm\n",
    "\n",
    "class L1LinearRegularisedClassifier(BaseEstimator,ClassifierMixin):\n",
    "   \n",
    "    def __init__(self,regularisationWeight =0.0, step = 0.0001,iterations = 5000):       \n",
    "        \n",
    "        self.regularisationWeight = regularisationWeight\n",
    "        self.step = step\n",
    "        self.theta = np.array(np.random.rand(X.shape[1]+1),dtype='float64')\n",
    "        \n",
    "        self.iterations = iterations\n",
    "    \n",
    "    def regularization(self,theta):\n",
    "        return self.regularisationWeight * norm(theta,0)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        self.stochastic_gradient_descent_L1(X,y,self.theta,self.iterations,self.step)\n",
    "        return self\n",
    "    \n",
    "    def stochastic_gradient_descent_L1(self,X,y,theta,I,step):\n",
    "        print theta.shape\n",
    "        print X.shape\n",
    "        Xchanged = np.concatenate((np.ones((X.shape[0],1),dtype='float64'),X),axis=1)\n",
    "        for it in range(I):\n",
    "            idx = np.random.randint(y.size)\n",
    "            gradCost = np.zeros(Xchanged.shape[1])\n",
    "            prod = np.dot(Xchanged[idx],self.theta)\n",
    "            gradCost = 2.0 * (y[idx]-prod)*Xchanged[idx]\n",
    "            \n",
    "            thetaPrime = self.theta + step*gradCost\n",
    "            for i in range(self.theta.size):\n",
    "                if self.theta[i]*thetaPrime[i] > 0 :\n",
    "                    self.theta[i] = 0\n",
    "                else :\n",
    "                    self.theta[i] = thetaPrime[i]\n",
    "            if it % 500 == 0:\n",
    "                y_pred = self.predict(X)\n",
    "                print it\n",
    "                print self.cost_function(y,y_pred,mean_squared_error,self.regularization), \"coût\"\n",
    "                print accuracy_score(y,y_pred), \"accuracy\"\n",
    "        \n",
    "    \n",
    "    def cost_function(self,y,y_pred,error_function,regularisation_function) :\n",
    "        cost = error_function(y,y_pred)-regularisation_function(self.theta)\n",
    "        return cost\n",
    "    \n",
    "    def stochastic_gradient_L1(self,theta,X,y,idx):\n",
    "        return 2.0 * (y-np.dot(theta,X))*X[idx]\n",
    "    \n",
    "    def linear_function(self,X,theta):\n",
    "        return np.dot(X,theta)\n",
    "    \n",
    "    \"\"\"def predict_with_theta(self, X, theta):\n",
    "        \n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        for i in range(X.shape[0]):\n",
    "            y_pred[i] = linear_function(X[i],theta)\n",
    "            if y_pred[i] > 0:\n",
    "                y_pred[i] = 1\n",
    "            else:\n",
    "                y_pred[i] = 0\n",
    "        return y_pred\"\"\"\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        Xchanged = np.concatenate((np.ones((X.shape[0],1),dtype='float64'),X),axis=1) \n",
    "        for i in range(Xchanged.shape[0]):\n",
    "            y_pred[i] = self.linear_function(Xchanged[i],self.theta)\n",
    "            if y_pred[i] > 0:\n",
    "                y_pred[i] = 1\n",
    "            else:\n",
    "                y_pred[i] = 0\n",
    "        return y_pred\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import fetch_mldata\n",
    "digits = datasets.load_digits(n_class = 2)\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "y = 2*y - 1\n",
    "print type(X[0][0])\n",
    "print type(y[0])\n",
    "print y[:10]\n",
    "classifieurL1= L1LinearRegularisedClassifier()\n",
    "scoresL1 = cross_validation.cross_val_score(classifieurL1, X, y, cv=5,scoring=\"accuracy\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1 -1  1 -1  1 -1 -1  1  1]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'theta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-231-a0cc1a9a7753>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[0mclassifieurL1\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mL1LinearRegularisedClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m scoresL1 = cross_validation.cross_val_score(classifieurL1, X, y, cv=5\n\u001b[0m\u001b[0;32m     81\u001b[0m )\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Walid\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m   1359\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m                                               fit_params)\n\u001b[1;32m-> 1361\u001b[1;33m                       for train, test in cv)\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Walid\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    657\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpre_dispatch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"all\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Walid\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36mdispatch\u001b[1;34m(self, func, args, kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m         \"\"\"\n\u001b[0;32m    405\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_verbosity_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Walid\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, args, kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Walid\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[0;32m   1457\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1458\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1459\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1461\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-231-a0cc1a9a7753>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstochastic_gradient_descent_L1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-231-a0cc1a9a7753>\u001b[0m in \u001b[0;36mstochastic_gradient_descent_L1\u001b[1;34m(self, X, y, theta, I, step)\u001b[0m\n\u001b[0;32m     41\u001b[0m                 \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_with_theta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m                 \u001b[1;32mprint\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregularization\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m                 \u001b[1;32mprint\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-153-037026ee57b9>\u001b[0m in \u001b[0;36mcost_function\u001b[1;34m(y, y_pred, error_function, regularisation_function)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merror_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mregularisation_function\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mregularisation_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mstochastic_gradient_L1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'theta' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "     \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.aclweb.org/anthology/P09-1054"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.array([1,2,3,4,5])\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5L,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = np.random.rand(6,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.61990672,  0.85698778,  0.30227644,  0.33878824,  0.99416707],\n",
       "       [ 0.62365261,  0.58393254,  0.54403266,  0.3566358 ,  0.09184679],\n",
       "       [ 0.85410289,  0.58495266,  0.94803139,  0.03989068,  0.29810894],\n",
       "       [ 0.74813547,  0.85936373,  0.35325312,  0.02635477,  0.24077968],\n",
       "       [ 0.18114573,  0.57853052,  0.06748894,  0.09179829,  0.12952997]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2001003949167433"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(A[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8%9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(np.ones(5),np.zeros(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
